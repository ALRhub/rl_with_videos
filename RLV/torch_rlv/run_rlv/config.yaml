---
name: "SLURM"   # MUST BE "SLURM"
# Required
partition: "single"
job-name: "RLV"    # this will be the experiments name in slurm
num_parallel_jobs: 10
ntasks: 1
cpus-per-task: 1
mem-per-cpu: 8000
time: 1440  # in minutes
sbatch_args: # Dictionary of SBATCH keywords and arguments
  distribution: cyclic  # To have repetitions of the same exp be distributed to different nodes
slurm_log: "./slurmlog/"


---
# DEFAULT parameters (Optional)
name: "DEFAULT"   #  useful for paralellization. defaults to 1.
reps_in_parallel: 8 # number of repetitions in each job that are executed in parallel. defaults to 1.

params:
  # this is where you specify all parameters needed for your experiment.MUST BE DEFAULT
  #path: "./output/rlv"   # location to save results in
  #repetitions: 3  # number of times one set of parameters is run
  #reps_per_job: 1 # number of repetitions in each job.
  # the tree structure you define here will be translated to a nested python dictionary
  # env_name: 'visual_door_opener_multi_world'
  # env_name: 'visual_door_opener_multi_world'
  env_name: 'acrobot_continuous'
  algo_name: 'sac'
  policy: 'MlpPolicy'
  lr_inverse_model: 0.0002
  wandb_log: False
  lr_sac: 0.0003
  buffer_size: 1000000
  learning_starts: 1000
  batch_size: 256
  tau: 0.005
  gamma: 0.99
  train_freq: 1
  gradient_steps: 1
  project_name: 'sac_experiment'
  run_name: 'test_sac'
  log_dir: '/tmp/gym/'

#---
#name: "sac_ex"
#path: "./output/sac/"
#repetitions: 5   # repeat 8 times
#
## Experiment Parameters
#params:
#  env_name: "acrobot_continuous"
#  algo_name: 'sac'
#  policy: 'MlpPolicy'


---
name: "rlv_ex"
path: "./output/rlv/"
repetitions: 1   # repeat 8 times

# Experiment Parameters
params:
  env_name: "acrobot_continuous"
  algo_name: 'rlv'
  policy: 'MlpPolicy'




